{\rtf1\ansi\ansicpg1252\cocoartf1344\cocoasubrtf720
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\fs24 \cf0 [cloudera@quickstart mapreduce]$ hadoop jar mapreduce_maxtemperature.jar MaxTemperature /user/cloudera/input/input.txt /user/cloudera/output3\
15/02/04 14:12:48 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\
15/02/04 14:12:49 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.\
15/02/04 14:12:49 INFO input.FileInputFormat: Total input paths to process : 1\
15/02/04 14:12:49 INFO mapreduce.JobSubmitter: number of splits:1\
15/02/04 14:12:50 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1423080402899_0001\
15/02/04 14:12:50 INFO impl.YarnClientImpl: Submitted application application_1423080402899_0001\
15/02/04 14:12:51 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1423080402899_0001/\
15/02/04 14:12:51 INFO mapreduce.Job: Running job: job_1423080402899_0001\
15/02/04 14:13:06 INFO mapreduce.Job: Job job_1423080402899_0001 running in uber mode : false\
15/02/04 14:13:06 INFO mapreduce.Job:  map 0% reduce 0%\
15/02/04 14:13:14 INFO mapreduce.Job:  map 100% reduce 0%\
15/02/04 14:13:24 INFO mapreduce.Job:  map 100% reduce 100%\
15/02/04 14:13:24 INFO mapreduce.Job: Job job_1423080402899_0001 completed successfully\
15/02/04 14:13:24 INFO mapreduce.Job: Counters: 49\
	File System Counters\
		FILE: Number of bytes read=61\
		FILE: Number of bytes written=211047\
		FILE: Number of read operations=0\
		FILE: Number of large read operations=0\
		FILE: Number of write operations=0\
		HDFS: Number of bytes read=656\
		HDFS: Number of bytes written=17\
		HDFS: Number of read operations=6\
		HDFS: Number of large read operations=0\
		HDFS: Number of write operations=2\
	Job Counters \
		Launched map tasks=1\
		Launched reduce tasks=1\
		Data-local map tasks=1\
		Total time spent by all maps in occupied slots (ms)=6410\
		Total time spent by all reduces in occupied slots (ms)=7056\
		Total time spent by all map tasks (ms)=6410\
		Total time spent by all reduce tasks (ms)=7056\
		Total vcore-seconds taken by all map tasks=6410\
		Total vcore-seconds taken by all reduce tasks=7056\
		Total megabyte-seconds taken by all map tasks=6563840\
		Total megabyte-seconds taken by all reduce tasks=7225344\
	Map-Reduce Framework\
		Map input records=5\
		Map output records=5\
		Map output bytes=45\
		Map output materialized bytes=61\
		Input split bytes=126\
		Combine input records=0\
		Combine output records=0\
		Reduce input groups=2\
		Reduce shuffle bytes=61\
		Reduce input records=5\
		Reduce output records=2\
		Spilled Records=10\
		Shuffled Maps =1\
		Failed Shuffles=0\
		Merged Map outputs=1\
		GC time elapsed (ms)=154\
		CPU time spent (ms)=1470\
		Physical memory (bytes) snapshot=356282368\
		Virtual memory (bytes) snapshot=1701855232\
		Total committed heap usage (bytes)=219480064\
	Shuffle Errors\
		BAD_ID=0\
		CONNECTION=0\
		IO_ERROR=0\
		WRONG_LENGTH=0\
		WRONG_MAP=0\
		WRONG_REDUCE=0\
	File Input Format Counters \
		Bytes Read=530\
	File Output Format Counters \
		Bytes Written=17\
}